# Fairness, Explainability, Interpretability, and Governance
A repo devoted to publicly available resources on fairness, explainability, interpretability, and governance in machine learning.

# Tutorials

[Farnadi, G., Liao, Q.V., Creager, E. (2022). *NeurIPS Tutorial: Algorithmic Fairness: At The Intersections*](https://neurips.cc/virtual/2022/tutorial/55815) 

[Cisse, M., Koyejo, S. (2019). *NeurIPS Tutorial: Representation Learning and Fairnesss*](https://nips.cc/Conferences/2019/Schedule?showEvent=13212) [(SlidesLive)](https://slideslive.com/38923185) [(Slides)](https://cs.stanford.edu/~sanmi/documents/Representation_Learning_Fairness_NeurIPS19_Tutorial.pdf)   

[Cisse, M., Russakovsky, O. (2022). *CVPR Tutorial: Algorithmic Fairness: Why it’s Hard, and Why it’s Interesting*](https://sites.google.com/view/cvpr2022-fairness-tutorial) [(Part 1)](https://www.youtube.com/watch?v=h_aAtC8zvKo) [(Part 2)](https://www.youtube.com/watch?v=h_aAtC8zvKo&t=0s) [(Slides)](https://drive.google.com/file/d/1AL6PgD5HXWscJ8RPl3sHBYBDihfL775m/view) 

[Black, E., Heidari, H., Ho, D. (2023) *NuerIPS Tutorial: Governance & Accountability for ML: Existing Tools, Ongoing Efforts, & Future Directions*](https://neurips.cc/virtual/2023/tutorial/73947)

# Workshops

[Lakkaraju H. (2022). *Stanford Workshop: Interpreting Machine Learning Models: State-of-the-art, Challenges, Opportunities*](https://www.youtube.com/playlist?list=PLoROMvodv4rPh6wa6PGcHH6vMG9sEIPxL) [(Slides)](https://docs.google.com/presentation/d/1khY_li29A5aUo_cEVRsvO8pcRn7Xp9Bi/mobilepresent?slide=id.p1)

[ICML 2021 Workshop on Algorithmic Recourse](https://icml.cc/Conferences/2021/ScheduleMultitrack?event=8363)

# Conferences

## Tailered Toward Fairness, Interpretability, or Explainability

[ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT)](https://facctconference.org/)

[AAAI/ACM Conference on Artificial Intelligence, Ethics, & Society (AIES)](https://www.aies-conference.com/2023/)

## Includes Content on Fairness, Interpretability, and Explainability

[Conference on Neural Information Processing Systems (NeurIPS)](https://neurips.cc/)

[International Conference on Learning Representations (ICLR)](https://iclr.cc/)

[International Conference on Machine Learning (ICML)](https://icml.cc/)

[IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)](https://cvpr2023.thecvf.com/)

[Conference on Uncertainty in Artificial Intelligence (UAI)](https://www.auai.org/uai2022/)

[ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)](https://kdd.org/kdd2023/)

[Conference on Artificial Intelligence and Statistics (AISTATS)](https://virtual.aistats.org/)

# Papers

Sorted from the perspective of interpretability, explainability, and fairness.

## Interpretability

[Letham, B., Rudin, C., McCormick, T. H., & Madigan, D. (2015). Interpretable Classifiers using Rules and Bayesian Analysis: Building a Better Stroke Prediction Model. *The Annals of Applied Statistics*](https://projecteuclid.org/journals/annals-of-applied-statistics/volume-9/issue-3/Interpretable-classifiers-using-rules-and-Bayesian-analysis--Building-a/10.1214/15-AOAS848.pdf)

[Rudin, C. (2019). Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and use Interpretable Models Instead. *Nature Machine Intelligence*](https://arxiv.org/pdf/1811.10154.pdf)

[Elhage, N., ... & Olah C. (2022). Softmax Linear Units. *Transformer Circuits Thread*](https://transformer-circuits.pub/2022/solu/index.html)

## Explainability

[Arya, V., Bellamy, R. K., Chen, P. Y., Dhurandhar, A., Hind, M., Hoffman, S. C., ... & Zhang, Y. (2019). One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques. *arXiv preprint arXiv:1909.03012*](https://arxiv.org/pdf/1909.03012.pdf)

[Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Giannotti, F., & Pedreschi, D. (2018). A Survey of Methods for Explaining Black Box Models. *ACM Computing Surveys (CSUR)*](https://dl.acm.org/doi/pdf/10.1145/3236009)

[Mahajan, D., Tan, C., & Sharma, A. (2019). Preserving Causal Constraints in Counterfactual Explanations for Machine Learning Classifiers. *arXiv preprint arXiv:1912.03277*](https://arxiv.org/pdf/1912.03277.pdf)

[Mothilal, R. K., Sharma, A., & Tan, C. (2020). Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations. *In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency.*](https://dl.acm.org/doi/pdf/10.1145/3351095.3372850)

[Liao, Q. V., Gruen, D., & Miller, S. (2020). Questioning the AI: Informing Design Practices for Explainable AI User Experiences. *In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems*](https://arxiv.org/pdf/1908.09635.pdf)

[Pawelczyk, M., Agarwal, C., Joshi, S., Upadhyay, S., & Lakkaraju, H. (2022). Exploring Counterfactual Explanations through the Lens of Adversarial Examples: A Theoretical and Empirical Analysis. *In International Conference on Artificial Intelligence and Statistics. PMLR.*](https://arxiv.org/pdf/2106.09992.pdf)

[Ustun, B., Spangher, A., & Liu, Y. (2019). Actionable Recourse in Linear Classification. *In Proceedings of the Conference on Fairness, Accountability, and Transparency*](https://arxiv.org/pdf/1809.06514.pdf)

[Verma, S., Dickerson, J., & Hines, K. (2020). Counterfactual Explanations for Machine Learning: A Review. *arXiv preprint arXiv:2010.10596*](https://arxiv.org/pdf/2010.10596.pdf)

[Wachter, S., Mittelstadt, B., & Russell, C. (2017). Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR. Harv. *JL & Tech*](https://jolt.law.harvard.edu/assets/articlePDFs/v31/Counterfactual-Explanations-without-Opening-the-Black-Box-Sandra-Wachter-et-al.pdf)

[Friedman, J. H. (2001). Greedy Function Approximation: A Gradient Boosting Machine. Annals of Statistics, 1189-1232. (Partial Dependence Plots)](https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-5/Greedy-function-approximation-A-gradient-boosting-machine/10.1214/aos/1013203451.pdf)

## Fairness

[Karimi, A. H., Barthe, G., Schölkopf, B., & Valera, I. (2022). A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations. *ACM Computing Surveys*](https://arxiv.org/pdf/2010.04050.pdf)

[Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). A Survey on Bias and Fairness in Machine Learning. *ACM Computing Surveys (CSUR)*](https://arxiv.org/pdf/1908.09635.pdf)

[Tran, C., Dinh, M., & Fioretto, F. (2021). Differentially Private Empirical Risk Minimization Under the Fairness Lens. *Advances in Neural Information Processing Systems*](https://proceedings.neurips.cc/paper/2021/file/e7e8f8e5982b3298c8addedf6811d500-Paper.pdf)

[Verma, S., & Rubin, J. (2018, May). Fairness Definitions Explained. *In 2018 IEEE/ACM International Workshop on Software Fairness (Fairware).*](https://vsahil.github.io/files/papers/Fairness_Definitions_Explained_2018.pdf)

[Castelnovo, A., Crupi, R., Greco, G. et al. (2022). A Clarification of The Nuances in The Fairness Metrics Landscape. *Sci Rep*](https://www.nature.com/articles/s41598-022-07939-1.pdf)

[Zemel, R., et al. (2013) Learning Fair Representations. *ICML*](https://www.cs.toronto.edu/~toni/Papers/icml-final.pdf)

## LLMs

[Kumar, S., Balachandran, V., Njoo, L., Anastasopoulos, A., Tsvetkov, Y. (2023) Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey. *EACL 2023*](https://arxiv.org/pdf/2210.07700.pdf) 

# Tools and Libraries

[Shap](https://github.com/slundberg/shap)

[Lime](https://github.com/marcotcr/lime)

[AI Fairness 360](https://github.com/Trusted-AI/AIF360)

[Fairlearn](https://github.com/fairlearn/fairlearn)

[InterpretML](https://github.com/interpretml/interpret)

[Captum](https://github.com/pytorch/captum)

[Quantus](https://github.com/understandable-machine-intelligence-lab/Quantus)

[Diverse Counterfactual Explanations (DiCE) for ML](https://github.com/interpretml/DiCE)

[Feasible Counterfactual Explanations](https://github.com/divyat09/cf-feasibility)

[OpenXAI](https://github.com/AI4LIFE-GROUP/OpenXAI)

[Aequitas](http://aequitas.dssg.io/)

# Regulations, Laws, Strategies, Guidelines, and Codes of Conduct

Several applicable documents regarding AI and ML. This is not a comprehensive list. 

## Canada

[Canadian Human Rights Act](https://laws-lois.justice.gc.ca/eng/acts/h-6/)

[AIDA - Artificial Intelligence and Data Act](https://www.parl.ca/legisinfo/en/bill/44-1/c-27)

[ISED - Voluntary Code of Conduct on the Responsible Development and Management of Advanced Generative AI Systems](https://ised-isde.canada.ca/site/ised/en/voluntary-code-conduct-responsible-development-and-management-advanced-generative-ai-systems)

## European Union

[Artificial Intelligence Act](https://www.consilium.europa.eu/en/press/press-releases/2022/12/06/artificial-intelligence-act-council-calls-for-promoting-safe-ai-that-respects-fundamental-rights/#:~:text=The%20Council%20has%20adopted%20its,fundamental%20rights%20and%20Union%20values.)

## UK

[National AI Strategy](https://www.gov.uk/government/publications/national-ai-strategy)

# People

[Q. Vera Liao](http://qveraliao.com/)

[Golnoosh Farnadi](https://gfarnadi.github.io/)

[Elliot Creager](https://www.cs.toronto.edu/~creager/)

[Hima Lakkaraju](https://himalakkaraju.github.io/)

[Cynthia Rudin](https://users.cs.duke.edu/~cynthia/)

[Rayid Ghani](https://www.rayidghani.com/)

# Posts

[Miller, K. (2021) Should AI Models Be Explainable? That Depends. *Standford University*](https://hai.stanford.edu/news/should-ai-models-be-explainable-depends)

[Millidge, B. & Black, S. (2022) The Singular Value Decompositions of Transformer Weight Matrices are Highly Interpretable. *AI Allignment Forum*](https://www.alignmentforum.org/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight)

[Kuo, C. (2020) Explain Your Model with the SHAP Values. *Medium*](https://medium.com/dataman-in-ai/explain-your-model-with-the-shap-values-bc36aac4de3d)

[H. Hajimirsadeghi, T. Durand, C. Srinivasa, V. Nagisetty (2022) Feature Importance and Explainability. *Borealis AI*](https://www.borealisai.com/research-blogs/feature-importance-and-explainability/)

[Prince, S. (2022) Explainability I: Local Post-hoc Explanations. *Borealis AI*](https://www.borealisai.com/research-blogs/explainability-i-local-post-hoc-explanations/)

[Prince, S. (2022) Explainability II: Global Explanations, Proxy Models, and Interpretable Models. *Borealis AI*](https://www.borealisai.com/research-blogs/explainability-ii-global-explanations-proxy-models-and-interpretable-models/)

[Krishna, D. Han, K. I., Sohail, O., Kaiser, P., Berendsen, S., Kampen, S., Lees, S. (2022) Unleashing the power of machine learning models in banking through explainable artificial intelligence (XAI). *Deloitte*](https://www.deloitte.com/global/en/our-thinking/insights/industry/financial-services/explainable-ai-in-banking.html)

# Courses and Additional Resources

[Interpretability and Explainability in Machine Learning. OMPSCI 282BR. *Harvard University*](https://interpretable-ml-class.github.io/)

[Explaining Machine Learning Predictions State-of-the-art, Challenges, and Opportunities](https://explainml-tutorial.github.io/)

[Trustworthy ML](https://www.trustworthyml.org/)

# Developer Guides

[Detect Posttraining Data and Model Bias with Amazon SageMaker Clarify](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-detect-post-training-bias.html)

[Google Developers - Machine Learning Glossary: Fairness](https://developers.google.com/machine-learning/glossary/fairness#reporting_bias)

# Fairness, Explainability, and Interpretability
A repo devoted to providing resources in fairness, explainability, and interprebility in machine learning.

# Regulations and Laws - Canada

[Canadian Human Rights Act](https://laws-lois.justice.gc.ca/eng/acts/h-6/)

[AIDA - Artificial Intelligence and Data Act](https://www.parl.ca/legisinfo/en/bill/44-1/c-27)

# Tutorials

[Farnadi, G., Liao, Q.V., Creager, E. (2022). *NeurIPS Tutorial: Algorithmic Fairness: At The Intersections*](https://neurips.cc/virtual/2022/tutorial/55815) 

# Workshops

[Lakkaraju H. (2022). *Stanford Workshop: Interpreting Machine Learning Models: State-of-the-art, Challenges, Opertunities*](https://www.youtube.com/playlist?list=PLoROMvodv4rPh6wa6PGcHH6vMG9sEIPxL) [(Slides)](https://docs.google.com/presentation/d/1khY_li29A5aUo_cEVRsvO8pcRn7Xp9Bi/mobilepresent?slide=id.p1)

# Papers

## Interpretability

[Letham, B., Rudin, C., McCormick, T. H., & Madigan, D. (2015). Interpretable Classifiers using Rules and Bayesian Analysis: Building a Better Stroke Prediction model. *The Annals of Applied Statistics*](https://projecteuclid.org/journals/annals-of-applied-statistics/volume-9/issue-3/Interpretable-classifiers-using-rules-and-Bayesian-analysis--Building-a/10.1214/15-AOAS848.pdf)

[Rudin, C. (2019). Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and use Interpretable Models Instead. *Nature Machine Intelligence*](https://arxiv.org/pdf/1811.10154.pdf)

## Explainability

[Arya, V., Bellamy, R. K., Chen, P. Y., Dhurandhar, A., Hind, M., Hoffman, S. C., ... & Zhang, Y. (2019). One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques. *arXiv preprint arXiv:1909.03012*](https://arxiv.org/pdf/1909.03012.pdf)

[Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Giannotti, F., & Pedreschi, D. (2018). A Survey of Methods for Explaining Black Box Models. *ACM Computing Surveys (CSUR)*](https://dl.acm.org/doi/pdf/10.1145/3236009)

[Liao, Q. V., Gruen, D., & Miller, S. (2020). Questioning the AI: Informing Design Practices for Explainable AI User Experiences. *In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems*](https://arxiv.org/pdf/1908.09635.pdf)

## Fairness

[Karimi, A. H., Barthe, G., Sch√∂lkopf, B., & Valera, I. (2022). A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations. *ACM Computing Surveys*](https://arxiv.org/pdf/2010.04050.pdf)

[Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). A Survey on Bias and Fairness in Machine Learning. *ACM Computing Surveys (CSUR)*](https://arxiv.org/pdf/1908.09635.pdf)

[Tran, C., Dinh, M., & Fioretto, F. (2021). Differentially Private Empirical Risk Minimization Under the Fairness Lens. *Advances in Neural Information Processing Systems*](https://proceedings.neurips.cc/paper/2021/file/e7e8f8e5982b3298c8addedf6811d500-Paper.pdf)

# Posts

[Miller, K. (2021) Should AI Models Be Explainable? That Depends. *Standford University*](https://hai.stanford.edu/news/should-ai-models-be-explainable-depends)

[Millidge, B. & Black, S. (2022) The Singular Value Decompositions of Transformer Weight Matrices are Highly Interpretable. *AI Allignment Forum*](https://www.alignmentforum.org/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight)

# Tools and Libraries

[AI Fairness 360 (Python and R)](https://github.com/Trusted-AI/AIF360)

[Fairlearn (Python)](https://github.com/fairlearn/fairlearn)

# People

[Q. Vera Liao](http://qveraliao.com/)

[Golnoosh Farnadi](https://gfarnadi.github.io/)

[Elliot Creager](https://www.cs.toronto.edu/~creager/)

[Hima Lakkaraju](https://himalakkaraju.github.io/)

[Cynthia Rudin](https://users.cs.duke.edu/~cynthia/)
